% FRE6871_Lecture_2
% Define knitr options
% !Rnw weave=knitr
% Set global chunk options
<<knitr_setup,include=FALSE,cache=FALSE>>=
library(knitr)
opts_chunk$set(prompt=TRUE, tidy=FALSE, strip.white=FALSE, comment=NA, highlight=FALSE, message=FALSE, warning=FALSE, size='scriptsize', fig.width=4, fig.height=4)
options(width=60, dev='pdf')
options(digits=3)
thm <- knit_theme$get("acid")
knit_theme$set(thm)
@


% Define document options
\documentclass[10pt]{beamer}
\mode<presentation>
\usetheme{AnnArbor}
% \usecolortheme{whale}
% Uncover everything in a step-wise fashion
% \beamerdefaultoverlayspecification{<+->}
% mathtools package for math symbols
% \usepackage{mathtools}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{fancybox}
\usepackage{url}
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % bibstyle=numeric
\usepackage{listings}
\usepackage{xcolor}
\definecolor{anti_flashwhite}{rgb}{0.95, 0.95, 0.96}
% \bibliographystyle{amsalpha} % doesn't work
\addbibresource{FRE_lectures.bib}
% \addbibresource[location=remote]{http://www.citeulike.org/user/jerzyp}
\renewcommand\bibfont{\footnotesize}
\renewcommand{\pgfuseimage}[1]{\scalebox{0.75}{\includegraphics{#1}}} % scale bib icons
\setbeamertemplate{bibliography item}[text] % set bib icons
% \setbeamertemplate{bibliography item}{} % remove bib icons

% \usepackage{enumerate}
% \let\emph\textbf
% \let\alert\textbf
% Define colors for hyperlinks
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks=true,linkcolor=,urlcolor=links}
% Make url text scriptsize
\renewcommand\UrlFont{\scriptsize}
% Make institute text italic and small
\setbeamerfont{institute}{size=\small,shape=\itshape}
\setbeamerfont{date}{size=\small}
\setbeamerfont{block title}{size=\normalsize} % shape=\itshape
\setbeamerfont{block body}{size=\footnotesize}


% Title page setup
\title[FRE6871 Lecture\#2]{FRE6871 \texttt{R} in Finance}
\subtitle{Lecture\#2, Spring 2020}

\institute[NYU Tandon]{NYU Tandon School of Engineering}
\titlegraphic{\includegraphics[scale=0.2]{image/tandon_long_color}}
\author[Jerzy Pawlowski]{Jerzy Pawlowski \emph{\href{mailto:jp3900@nyu.edu}{jp3900@nyu.edu}}}
% \email{jp3900@nyu.edu}
\date{March 16, 2020}
% \date{\today}
% \pgfdeclareimage[height=0.5cm]{university-logo}{engineering_long_white}
% \logo{\pgfuseimage{engineering_long_white}}


%%%%%%%%%%%%%%%
\begin{document}


%%%%%%%%%%%%%%%
\maketitle



%%%%%%%%%%%%%%%
\section{Functions}


%%%%%%%%%%%%%%%
\subsection{\secname \hskip0.4em in \texttt{R}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \texttt{R} functions have three components:
      \begin{itemize}
        \item a list of formal arguments,
        \item a body containing \texttt{R} code,
        \item an environment,
      \end{itemize}
      An \texttt{R} function plus its environment is referred to as a function \emph{closures}.
      \vskip1ex
      The function body should be enclosed in curly braces \texttt{\{\}}, unless it contains a single command, then it doesn't have to enclosed.
      \vskip1ex
      The function body doesn't require a \texttt{return} statement, since by default \texttt{R} functions return the last statement evaluated in the body.
      \vskip1ex
      \texttt{args()} displays the formal arguments of a function.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Define a function with two arguments
test_func <- function(first_arg, second_arg) {  # Body
  first_arg + second_arg  # Returns last evaluated statement
}  # end test_func

test_func(1, 2)  # Apply the function
args(test_func)  # Display argument

# Define function that uses variable from enclosure environment
test_func <- function(first_arg, second_arg) {
  first_arg + second_arg + glob_var
}  # end test_func

test_func(3, 2)  # error - glob_var doesn't exist yet!
glob_var <- 10  # Create glob_var
test_func(3, 2)  # now works
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Return Values of \secname}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The function body doesn't require a \texttt{return} statement, since by default \texttt{R} functions return the last statement evaluated in the body.
      \vskip1ex
      \texttt{return()} statements are inserted in logical branches to terminate function execution and return its intended value.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Define function that returns NULL for non-numeric argument
test_func <- function(in_put) {
  if (!is.numeric(in_put)) {
    warning(paste("argument", in_put, "isn't numeric"))
    return(NULL)
  }
  2*in_put
}  # end test_func

test_func(2)
test_func("hello")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\secname \hskip0.4em That Return \texttt{invisible}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      If a return value is wrapped in the function \texttt{invisible()} then the return value isn't printed.
      \vskip1ex
      But if the function is assigned to a variable, then its return value is assigned to that variable.
      \vskip1ex
      \texttt{invisible()} allows creating functions whose return values can be assigned, but which do not print when they're not assigned.
      \vskip1ex
      The function \texttt{load()} reads data from \texttt{.RData} files, and \emph{invisibly} returns a vector of names of objects created in the workspace.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Define a function that returns invisibly
return_invisible <- function(in_put) {
  invisible(in_put)
}  # end return_invisible

return_invisible(2)

glob_var <- return_invisible(2)
glob_var

rm(list=ls())  # Remove all objects
# Load objects from file
loaded <- load(file="C:/Develop/data/my_data.RData")
loaded  # Vector of loaded objects
ls()  # List objects
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Binding Function Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The formal arguments of a function are defined in its argument list.
      \vskip1ex
      When a function is called, it's passed a list of actual function arguments.
      \vskip1ex
      Formal arguments can be \emph{bound} to actual arguments either by name or by position:
      \begin{itemize}
        \item by name: formal arguments are \emph{bound} to actual arguments with the same name,
        \item by position: the first formal argument is \emph{bound} to the first actual argument, etc.
      \end{itemize}
      \emph{Binding} by name takes precedence over \emph{binding} by position: first all the named arguments are \emph{bound}, then the remaining arguments are \emph{bound} by position.
      \vskip1ex
      Partial argument names are \emph{bound} to full names.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
test_func <- function(first_arg, second_arg) {
# Last statement of function is return value
  first_arg + 2*second_arg
}  # end test_func
test_func(first_arg=3, second_arg=2)  # Bind by name
test_func(first=3, second=2)  # Partial name binding
test_func(3, 2)  # Bind by position
test_func(second_arg=2, 3)  # mixed binding
test_func(3, 2, 1)  # too many arguments
test_func(2)  # not enough arguments
      @
      \vspace{-1em}
      All the actual arguments must be \emph{bound} to formal arguments, and if not then an \texttt{"unused argument"} error is produced.
      \vskip1ex
      If there aren't enough formal arguments, then an \texttt{"argument is missing"} error is produced,
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Default Values for Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Formal arguments may be assigned default values, so that when the actual arguments are missing then their default values are used instead.
      \vskip1ex
      Default values are often assigned to function parameters, that determine the function's behavior.
      \vskip1ex
      Default values can be specified as a vector of strings, representing the possible values of a function's parameter.
      \vskip1ex
      The function \texttt{match.arg()} matches a string to one of the possible values, and returns the matched value, or produces an \texttt{error} if it can't match it.
      \vskip1ex
      The function \texttt{str()} displays the structure of an \texttt{R} object, for example a function name and its formal arguments.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Function "paste" has two arguments with default values
str(paste)
# Default values of arguments can be specified in argument list
test_func <- function(first_arg, fac_tor=1) {
  fac_tor*first_arg
}  # end test_func
test_func(3)  # Default value used for second argument
test_func(3, 2)  # Default value over-ridden
# Default values can be a vector of strings
test_func <- function(in_put=c("first_val", "second_val")) {
  in_put <- match.arg(in_put)  # Match to arg list
  in_put
}  # end test_func
test_func("second_val")
test_func("se")  # Partial name binding
test_func("some_val")  # Invalid string
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Function for Calculating Skew}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} provides an easy way for users to write functions.
      \vskip1ex
      Formal function arguments can be bound to input variables by position or by name.
      \vskip1ex
      If the function arguments are missing then their default value is used.
      \vskip1ex
      Functions return the value of the last expression that is evaluated.
      \vskip1ex
      \texttt{datasets} is a \texttt{base} package containing various datasets, for example: \texttt{EuStockMarkets}.
      \vskip1ex
      The \texttt{EuStockMarkets} dataset contains daily closing prices of european stock indices.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# DAX percentage returns
re_turns <- rutils::diff_it(log(EuStockMarkets[, 1]))
# Calc_skew() calculates skew of time series of returns
# Default is normal time series
calc_skew <- function(se_ries=rnorm(1000)) {
  # number of observations
  len_gth <- NROW(se_ries)
  # normalize se_ries
  se_ries <-
    (se_ries - mean(se_ries))/sd(se_ries)
  # Calculate skew - last statement automatically returned
  len_gth*sum(se_ries^3)/((len_gth-1)*(len_gth-2))
}  # end calc_skew

# Calculate skew of DAX returns
# Bind arguments by name
calc_skew(se_ries=re_turns)
# Bind arguments by position
calc_skew(re_turns)
# Use default value of arguments
calc_skew()
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The dots \texttt{"..."} Function Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The dots \texttt{"..."} function argument is a formal argument without a name, as opposed to the other formal arguments which all have names.
      \vskip1ex
      The dots \texttt{"..."} bind with any number of additional arguments, that aren't already bound by name or position to the named arguments.
      \vskip1ex
      The dots \texttt{"..."} are used when the number of arguments isn't known in advance, and allows functions to accept an indefinite number of arguments.
      \vskip1ex
      The dots \texttt{"..."} are sometimes placed \emph{after} the named arguments, to allow passing of additional parameters into a function.
      \vskip1ex
      \emph{Functionals} often place the dots \texttt{"..."} argument \emph{after} the named arguments, to allow passing the dots \texttt{"..."} to the function being called by the \emph{functional}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE>>=
str(plot)  # Dots for additional plot parameters
bind_dots <- function(in_put, ...) {
  paste0("in_put=", in_put,
         ", dots=", paste(..., sep=", "))
}  # end bind_dots
bind_dots(1, 2, 3)  # "in_put" bound by position
bind_dots(2, in_put=1, 3)  # "in_put" bound by name
bind_dots(1, 2, 3, foo=10)  # named argument bound to dots
bind_dots <- function(arg1, arg2, ...) {
  arg1 + 2*arg2 + sum(...)
}  # end bind_dots
bind_dots(3, 2)  # Bind arguments by position
bind_dots(3, 2, 5, 8)  # Extra arguments bound to dots
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Argument Binding With dots \texttt{"..."} Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The dots \texttt{"..."} argument is sometimes placed \emph{before} the named arguments, so that a function can accept an indefinite number of arguments, without binding them by position with the named arguments.
      \vskip1ex
      When the dots \texttt{"..."} are placed \emph{before} the named arguments, the named arguments are often assigned default values, so they don't have to be bound to a value in the call.
      \vskip1ex
      Arguments that appear after the dots \texttt{"..."} must be \emph{bound} by their full name, and can't be partially \emph{bound}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE>>=
str(sum)  # Dots before other arguments
sum(1, 2, 3)  # Dots bind before other arguments
sum(1, 2, NA, 3, na.rm=TRUE)
bind_dots <- function(..., in_put) {
  paste0("in_put=", in_put,
         ", dots=", paste(..., sep=", "))
}  # end bind_dots
# Arguments after dots must be bound by full name
bind_dots(1, 2, 3, in_put=10)
bind_dots(1, 2, 3, in_put=10, foo=4)  # Dots bound
bind_dots(1, 2, 3)  # "in_put" not bound
bind_dots <- function(..., in_put=10) {
  paste0("in_put=", in_put,
         ", dots=", paste(..., sep=", "))
}  # end bind_dots
bind_dots(1, 2, 3)  # "in_put" not bound, but has default
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Wrapper \secname \hskip0.4em With dots \texttt{"..."} Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \emph{Wrapper} functions provide a convenient user interface to functions, by assigning default argument values, validating data, and formatting the output.
      \vskip1ex
      \emph{Wrapper} functions are designed to perform the actions of other functions, while reducing their complexity.
      \vskip1ex
      The dots \texttt{"..."} argument of the \emph{wrapper} function allows passing additional arguments on to the wrapped function.
      \vskip1ex
      \emph{Wrapper} functions should be used with caution, since wrapping a function creates extra code (overhead), which slows down \texttt{R}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Wrapper for mean() with default na.rm=TRUE
my_mean <- function(x, na.rm=TRUE, ...) {
  mean(x=x, na.rm=na.rm, ...)
}  # end my_mean
foo <- sample(c(1:10, NA, rep(0.1, t=5)))
mean(c(foo, NA))
mean(c(foo, NA), na.rm=TRUE)
my_mean(c(foo, NA))
my_mean(c(foo, NA), trim=0.4)  # Pass extra argument
# Wrapper for saving data into default directory
save_data <- function(...,
                      file=stop("error: no file name"),
                      my_dir="C:/Develop/data") {
# Create file path
  file <- file.path(my_dir, file)
  save(..., file=file)
}  # end save_data
foo <- 1:10
save_data(foo, file="scratch.RData")
save_data(foo, file="scratch.RData", my_dir="C:/Develop")
# Wrapper for testing negative arguments
stop_if_neg <- function(in_put) {
  if (!is.numeric(in_put) || in_put<0)
    stop("argument not numeric or negative")
}  # end stop_if_neg
# Wrapper for sqrt()
my_sqrt <- function(in_put) {
  stop_if_neg(in_put)
  sqrt(in_put)
}  # end my_sqrt
my_sqrt(2)
my_sqrt(-2)
my_sqrt(NA)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Recursive \secname \hskip0.4em with dots \texttt{"..."} Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \emph{Recursive} functions can also accept the dots \texttt{"..."} argument.
      \vskip1ex
      The dots \texttt{"..."} argument can be referenced inside a function by first converting it into a list using \texttt{"list(...)"}.
      \vskip1ex
      The function \texttt{missing()} returns \texttt{TRUE} if an argument is missing, and \texttt{FALSE} otherwise.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Recursive function sums its argument list
sum_dots <- function(in_put, ...) {
  if (missing(...)) {  # Check if dots are empty
    return(in_put)  # just one argument left
  } else {
    in_put + sum_dots(...)  # Sum remaining arguments
  }  # end if
}  # end sum_dots
sum_dots(1, 2, 3, 4)
# Recursive function sums its argument list
sum_dots <- function(in_put, ...) {
  if (NROW(list(...)) == 0) {  # Check if dots are empty
    return(in_put)  # just one argument left
  } else {
    in_put + sum_dots(...)  # Sum remaining arguments
  }  # end if
}  # end sum_dots
sum_dots(1, 2, 3, 4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Recursive Function for Calculating Fibonacci Sequence}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \emph{Recursive} functions call themselves in their own body.
      \vskip1ex
      The \emph{Fibonacci} sequence of integers is defined by the recurrence relation:
      \begin{displaymath}
        F_n = F_{n-1} + F_{n-2},
      \end{displaymath}
      \begin{displaymath}
        F_1 = 0, F_2 = 1,
      \end{displaymath}
      \begin{displaymath}
        F_n = 0, 1, 1, 2, 3, 5, 8, 13, \ldots
      \end{displaymath}
      The \emph{Fibonacci} sequence was invented by \emph{Indian} mathematicians, and later described by the Italian mathematician \emph{Fibonacci} in his famous treatise \emph{Liber Abaci}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE>>=
fibo_nacci <- function(len_gth) {
  if (len_gth > 2) {
    fib_seq <- fibo_nacci(len_gth-1)  # Recursion
    c(fib_seq, sum(tail(fib_seq, 2)))  # Return this
  } else {
    c(0, 1)  # Initialize and return
  }
}  # end fibo_nacci
fibo_nacci(10)
tail(fibo_nacci(9), 2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exploring Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      If a function name is called alone without arguments, then \texttt{R} displays the function code (but it must be on the search path).
      \vskip1ex
      Non-visible objects can't be viewed by calling their name.
      \vskip1ex
      The function \texttt{getAnywhere()} displays information about \texttt{R} objects, including non-visible objects.
      \vskip1ex
      The function \texttt{getAnywhere()} also displays \texttt{R} objects that aren't on the search path.
    \column{0.6\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Show the function code
plot.default
# Display function
getAnywhere(plot.default)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Internal and Primitive Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \texttt{R} is a high-level language written in lower-level languages, mostly \texttt{C++} and some \texttt{Fortran}.
      \vskip1ex
      \texttt{R} functions are either written in \texttt{R} code (\emph{interpreted} functions), or they directly call compiled \texttt{C++} or \texttt{Fortran} code (\emph{compiled} functions, also called \emph{internal} or \emph{primitive}).
      \vskip1ex
      \texttt{R} parses the code of \emph{interpreted} functions, and eventually calls compiled \texttt{C++} or \texttt{Fortran} code.
      \vskip1ex
      But this extra processing makes \emph{interpreted} functions much slower than \emph{compiled} functions.
      \vskip1ex
      Users can distinguish between \emph{interpreted} functions and \emph{compiled} functions by typing their names, and analyzing their source code.
      \vskip1ex
      The source code of \emph{interpreted} functions contains multiple lines of \texttt{R} code, or a call to function \texttt{UseMethod()} (which \emph{dispatches} \emph{methods} associated with \emph{generic} functions).
      \vskip1ex
      The source code of \emph{compiled} functions contains a single call to one of the functions that execute \emph{compiled} \texttt{C++} or \texttt{Fortran} code: \texttt{.Internal()}, \texttt{.Primitive()}, \texttt{.C()}, \texttt{.Call()}, \texttt{.Fortran()}, or \texttt{.External()}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE, eval=FALSE>>=
# Sum() is a compiled primitive function
sum
# mean() is a generic function
mean
# Show all methods of mean()
methods(generic.function=mean)
# Show code for mean.default()
mean.default
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Exploring Internal and Primitive Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Several functions call compiled code: \texttt{.C()}, \texttt{.Call()}, \texttt{.Fortran()}, \texttt{.External()}, or \texttt{.Internal()} and \texttt{.Primitive()}
      \vskip1ex
      \texttt{R} \texttt{.Internal()} \texttt{.Primitive()}
      \vskip1ex
      The function \texttt{getAnywhere()} displays \texttt{R} objects, including functions.
      \vskip1ex
      If a function name is called alone then \texttt{R} displays the function code (but it must be on the search path).
      \vskip1ex
      the user can access symbols from a package that isn't attached using the double-colon operator \texttt{tools::file\_ext}

      The function \texttt{getAnywhere()} also displays \texttt{R} objects that aren't on the search path.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Get all methods for generic function "plot"
methods("plot")

getAnywhere(plot)  # Display function
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Lazy Evaluation of Function Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \texttt{R} functions delay evaluation of their arguments until they're needed by their \texttt{R} code.
      \vskip1ex
      This is called \emph{lazy} evaluation.
      \vskip1ex
      If the function body doesn't evaluate an argument, then the function won't produce an error, even if the argument is missing.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
lazy_func <- function(arg1, arg2) {  # Define function lazy_func
  2*arg1  # just multiply first argument
}  # end lazy_func
lazy_func(3, 2)  # Bind arguments by position
lazy_func(3)  # Second argument was never evaluated!
lazy_func <- function(arg1, arg2) {  # Define function lazy_func
  cat(arg1, '\n')  # Write to output
  cat(arg2)  # Write to output
}  # end lazy_func
lazy_func(3, 2)  # Bind arguments by position
lazy_func(3)  # First argument written to output
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Function Environments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      When a function is called, a new \emph{evaluation} environment is created.
      \vskip1ex
      The \emph{evaluation} environment contains the function arguments and locally defined variables.
      \vskip1ex
      \texttt{R} evaluates variables inside functions by searching first in the \emph{evaluation} environment, then the \emph{enclosure} environment, then the \texttt{R} search path.
      \vskip1ex
      The enclosure of the \emph{evaluation} environment is the environment where the function was defined.
      \vskip1ex
      The enclosure of functions defined in the workspace is the \emph{global} environment.
      \vskip1ex
      The enclosure of functions defined in packages is the package \emph{namespace}.
      \vskip1ex
      Objects defined in the function enclosure can be referenced inside the function.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
glob_var <- 1  # Define a global variable
ls(environment())  # Get all variables in environment
func_env <- function() {  # Explore function environments
  loc_var <- 1  # Define a local variable
  cat('objects in evaluation environment:\t',
      ls(environment()), '\n')
  cat('objects in enclosing environment:\t',
      ls(parent.env(environment())), '\n')
  cat('this is the enclosing environment:')
  parent.env(environment())  # Return enclosing environment
}  # end func_env
func_env()

environment(func_env)
environment(print)  # Package namespace is the enclosure
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Lexical Function Scope}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      A \emph{free} variable is a variable that's not included in the \emph{evaluation} environment.
      \vskip1ex
      Scoping rules determine how \emph{free} variables are evaluated.
      \vskip1ex
      By default \texttt{R} uses \emph{lexical} (\emph{static}) scoping, which means that variables are first evaluated in the \emph{evaluation} environment, then in the \emph{enclosing} environment in which the function was \emph{defined}, and so on.
      \vskip1ex
      \emph{Dynamic} scoping means that variables are evaluated in the environment from which the function was \emph{called}.
      \vskip1ex
      The standard assignment operator \texttt{"<-"} modifies variables in the \emph{evaluation} environment.
      \vskip1ex
      The special assignment operator \texttt{"<<-"} modifies variables in the \emph{enclosing} environment,

    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
glob_var <- 1  # Define a global variable
probe_scope <- function() {  # Explore function scope
  loc_var <- 2*glob_var  # Define a local variable
  new_globvar <<- 11  # Define a global variable
  cat('objects in evaluation environment:\t',
      ls(environment()), '\n')
  cat('this is a local loc_var:\t', loc_var, '\n')
  cat('objects in enclosing environment:\n',
      ls(parent.env(environment())), '\n')
  cat('this is glob_var:\t', glob_var, '\n')
  glob_var <- 10  # Define local glob_var
  cat('this is the local glob_var:\t', glob_var, '\n')
}  # end probe_scope
probe_scope()
glob_var  # Global variable is unaffected
new_globvar  # new_globvar is preserved
loc_var  # Local variable is gone!
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Argument Passing in \texttt{R}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      In general, arguments can be passed into functions either by \emph{value} or by \emph{reference}.
      \vskip1ex
      When an argument is passed by \emph{value}, then a copy of that argument is passed to the function.
      \vskip1ex
      That way if the function modifies that argument, then the original object isn't modified.
      \vskip1ex
      When an argument is passed by \emph{reference}, then a \emph{pointer} to the original object is passed to the function.
      \vskip1ex
      If the function modifies that argument, then the original object is modified as well.
      \vskip1ex
      \texttt{R} uses a hybrid method of argument passing called \emph{copy-on-modify semantics}.
      \vskip1ex
      \texttt{R} passes arguments by reference, thus saving memory space and time for copying.
      \vskip1ex
      But if the argument is modified within the function, then \texttt{R} makes a copy of it, so that the original object is unchanged.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
a <- 1  # Define a variable
# New variable "b" points to value of "a"
b <- a  # Define a new variable
# When "b" is modified, R makes a copy of it
b <- b+1
# Function doubles its argument and returns it
double_it <- function(in_put) {
  in_put <- 2*in_put
  cat("input argument was doubled to:", in_put, "\n")
  in_put
}
double_it(a)
a  # variable "a" is unchanged
      @
      \emph{Copy-on-modify semantics} has important implications for performance and memory usage.
      \vskip1ex
      \url{http://stackoverflow.com/questions/15759117/what-exactly-is-copy-on-modify-semantics-in-r-and-where-is-the-canonical-source}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Side effects Using the Super-assignment Operator \texttt{"<<-"}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Function \emph{side effects} are operations on objects outside a function's \emph{evaluation} environment.
      \vskip1ex
      The functions \texttt{plot()} and \texttt{load()} are examples of functions that produce \emph{side effects}.
      \vskip1ex
      \texttt{load()} reads data from an \texttt{.RData} file, and creates objects in the workspace that are contained in the \texttt{.RData} file.
      \vskip1ex
      The super-assignment operator \texttt{"<<-"} allows creating functions that produce \emph{side effects}.
      \vskip1ex
      The super-assignment operator \texttt{"<<-"} modifies or creates variables in the \emph{enclosing} environment in which a function was \emph{defined} (\emph{lexical} scoping).
      \vskip1ex
      If a function was \emph{defined} in the \emph{global} environment then that's the function's \emph{enclosing} environment, and the \texttt{"<<-"} operator operates on variables in the \emph{global} environment.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-(1:1))>>=
setwd("C:/Develop/lecture_slides/data")
rm(list=ls())  # Remove all objects
ls()  # List objects
# Load objects from file (side effect)
load(file="my_data.RData")
ls()  # List objects
glob_var <- 1  # Define a global variable
# Explore function scope and side effects
side_effect <- function() {
  cat("global glob_var:\t", glob_var, "\n")
# Define local "glob_var" variable
  glob_var <- 10
# Re-define the global "glob_var"
  glob_var <<- 2
  cat("local glob_var:\t", glob_var, "\n")
}  # end side_effect
side_effect()
# Global variable was modified as side effect
glob_var
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Operators as Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Most functions in \texttt{R} are \emph{prefix} operators (where the function name is followed by a list of arguments).
      \vskip1ex
      \emph{Infix} operators (where the the function name comes in between its arguments) can also be applied using \emph{prefix} syntax.
      \vskip1ex
      In \emph{prefix} syntax, the \emph{Infix} operator name must be surrounded by single \texttt{''} or double  \texttt{""} quotes.
      \vskip1ex
      The \texttt{"["} bracket operator can also be written as a \emph{prefix} function.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Standard infix operator call syntax
2 + 3
# Infix operator applied using prefix syntax
"+"(2, 3)
# Standard bracket operator
vec_tor <- c(4, 3, 5, 6)
vec_tor[2]
# Bracket operator applied using prefix syntax
"["(vec_tor, 2)

      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Defining New Infix Operators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      New \emph{infix} operators can be defined using the usual function definition syntax.
      \vskip1ex
      All user defined \emph{infix} operators names must be nested between \texttt{"\%"} characters.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Define infix operator that returns string
'%+%' <- function(a, b) paste(a, b, sep=" + ")
2 %+% 3
2 %+% 3 %+% 4
"hello" %+% 2 %+% 3 %+% "bye"
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Replacement Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \texttt{R} syntax allows assigning to the values returned by functions, but they must be defined as \emph{replacement} functions.
      \vskip1ex
      \emph{replacement} function names include the assignment arrow: \texttt{"name<-"}.
      \vskip1ex
      The first argument passed to the \emph{replacement} function is modified by the second argument, and then it's returned.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
obj_string <- "hello"
class(obj_string)
# Assign to value returned by "class" function
class(obj_string) <- "string"
class(obj_string)
# Define function last()
last <- function(vec_tor) {
  vec_tor[NROW(vec_tor)]
}  # end last
last(1:10)
# Define replacement function last()
'last<-' <- function(vec_tor, value) {
  vec_tor[NROW(vec_tor)] <- value
  vec_tor
}  # end last
x <- 1:5
last(x) <- 11
x
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Higher order Functions}


%%%%%%%%%%%%%%%
\subsection{Functions as First Class Objects}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      Functions in \texttt{R} are \emph{first class objects}, which means they can be treated like any other \texttt{R} object:
      \begin{itemize}
        \item Functions can be passed as arguments to other functions,
        \item Functions can be nested (defined inside other functions),
        \item Functions can return functions as their return value,
      \end{itemize}
      \emph{Higher order} functions are \texttt{R} functions that either accept a function as their argument (input) or return a function as their value (output).
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Create functional that accepts a function as input argument
func_tional <- function(func_name) {
# Calculates statistic on random numbers
  set.seed(1)
  func_name(runif(1e4))  # Apply the function name
}  # end func_tional
func_tional(mean)
func_tional(sd)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functions That Return Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \texttt{R} functions can also return a function as their value.
      \vskip1ex
      Functions returned by a function are called \emph{closures}.
      \vskip1ex
      Functions that return closures can be used as \emph{function factories}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Define a power function factory
make_func <- function(arg_param) {  # Wrapper function
  function(in_put) {  # Anonymous closure
    in_put^arg_param
  }
}  # end make_func

square_func <- make_func(2)  # Define square function
square_func(4)
cube_func <- make_func(3)  # Define cube function
cube_func(2)
cube_root_func <- make_func(1/3)  # Define cube root function
cube_root_func(8)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Functionals}


%%%%%%%%%%%%%%%
\subsection{Functionals}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \emph{Functionals} are functions that accept a function or a function name (string) as one of their input arguments.
      \vskip1ex
      \emph{Functionals} are able to execute function calls using the function names.
      \vskip1ex
      The function \texttt{match.fun()} returns a function name that is specified by a string.
      \vskip1ex
      \emph{Functionals} that call \texttt{match.fun()} are able to accept a string as a function name, because \texttt{match.fun()} converts it to a function.
      \vskip1ex
      \texttt{match.fun()} produces an error condition if it fails to find a function with the specified name.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Func_tional accepts function name and additional argument
func_tional <- function(func_name, in_put) {
# Produce function name from argument
  func_name <- match.fun(func_name)
# Execute function call
  func_name(in_put)
}  # end func_tional
func_tional(sqrt, 4)
# String also works because match.fun() converts it to a function
func_tional("sqrt", 4)
str(sum)  # Sum() accepts multiple arguments
# Func_tional can't accept indefinite number of arguments
func_tional(sum, 1, 2, 3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functionals with dots \texttt{"..."} Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The dots \texttt{"..."} argument in \emph{functionals} can be used to pass additional arguments to the function being called by the \emph{functional}.
      \vskip1ex
      If named values are passed to the dots \texttt{"..."} argument, then the \emph{functional} can bind them to the correct formal arguments of the function being called by the \emph{functional}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Func_tional accepts function name and dots '...' argument
func_tional <- function(func_name, ...) {
  func_name <- match.fun(func_name)
  func_name(...)  # Execute function call
}  # end func_tional
func_tional(sum, 1, 2, 3)
func_tional(sum, 1, 2, NA, 4, 5)
func_tional(sum, 1, 2, NA, 4, 5, na.rm=TRUE)
# Function with three arguments and dots '...' arguments
my_func <- function(in_put, param1, param2, ...) {
  c(input=in_put, param1=param1, param2=param2,
        dots=c(...))
}  # end my_func
my_func(1, 2, 3, param2=4, param1=5)
func_tional(my_func, 1, 2, 3, param2=4, param1=5)
func_tional(my_func, 1, 2, 3, 4, 5)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Anonymous Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \texttt{R} allows defining functions without assigning a name to them.
      \vskip1ex
      \emph{Anonymous} functions are functions that are not assigned to a name.
      \vskip1ex
      \emph{Anonymous} functions can be passed as arguments to \emph{functionals}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Simple anonymous function
(function(x) (x + 3)) (10)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Functionals with Anonymous Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      \emph{Anonymous} functions can be passed as arguments to \emph{functionals}.
      \vskip1ex
      \emph{Anonymous} functions can also be used as default values for function arguments.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Anonymous function passed to func_tional
func_tional(func_name=(function(x) (x + 3)), 5)
# Anonymous function is default value
func_tional <-
  function(..., func_name=function(x, y, z) {x+y+z}) {
    func_name <- match.fun(func_name)
    func_name(...)  # Execute function call
}  # end func_tional
func_tional(2, 3, 4)  # Use default func_name
func_tional(2, 3, 4, 5)
# Func_name bound by name
func_tional(func_name=sum, 2, 3, 4, 5)
# Pass anonymous function to func_name
func_tional(func_name=function(x, y, z) {x*y*z},
            2, 3, 4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Executing Function Calls Using the \texttt{do.call()} Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functional \texttt{do.call()} executes a function call using a function name and a list of arguments.
      \vskip1ex
      \texttt{do.call()} allows calling a function on arguments that are elements of a list.
      \vskip1ex
      \texttt{do.call()} passes the list elements individually, instead of passing the whole list as one argument:\\
      \texttt{do.call(fun, list)=
      fun(list[[1]], list[[2]], \ldots)}
      \vskip1ex
      \texttt{do.call()} can be called inside other \emph{functionals} to allow them to execute function calls.
      \vskip1ex
      The function \texttt{str()} displays the structure of an \texttt{R} object, for example a function name and its formal arguments.
      \vskip1ex
      The function \texttt{do\_call()} from package \emph{rutils} performs the same operation as \texttt{do.call()}, but using recursion, which is much faster and uses less memory.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
str(sum)  # Sum() accepts multiple arguments
# Sum() can't accept list of arguments
sum(list(1, 2, 3))
str(do.call)  # "what" argument is a function
# Do.call passes list elements into "sum" individually
do.call(sum, list(1, 2, 3))
do.call(sum, list(1, 2, NA, 3))
do.call(sum, list(1, 2, NA, 3, na.rm=TRUE))
# Func_tional() accepts list with function name and arguments
func_tional <- function(list_arg) {
# Produce function name from argument
  func_name <- match.fun(list_arg[[1]])
# Execute function call uing do.call()
  do.call(func_name, list_arg[-1])
}  # end func_tional
arg_list <- list("sum", 1, 2, 3)
func_tional(arg_list)
# Do_call() performs same operation as do.call()
all.equal(
  do.call(sum, list(1, 2, NA, 3, na.rm=TRUE)),
  rutils::do_call(sum, list(1, 2, NA, 3), na.rm=TRUE))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Performing Loops Using the \texttt{apply()} \secname}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      An important example of \emph{functionals} are the \texttt{apply()} functionals.
      \vskip1ex
      The functional \texttt{apply()} returns the result of applying a function to the rows or columns of an array or matrix.
      \vskip1ex
      If \texttt{MARGIN=1} then the function will be applied over the matrix \emph{rows,}
      \vskip1ex
      If \texttt{MARGIN=2} then the function will be applied over the matrix \emph{columns}.
      \vskip1ex
      \texttt{apply()} performs a loop over the list of objects, and can replace \texttt{"for"} loops in \texttt{R}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
str(apply)  # Get list of arguments
# Create a matrix
mat_rix <- matrix(6:1, nrow=2, ncol=3)
mat_rix
# Sum the rows and columns
row_sums <- apply(mat_rix, 1, sum)
col_sums <- apply(mat_rix, 2, sum)
mat_rix <- cbind(c(sum(row_sums), row_sums),
                  rbind(col_sums, mat_rix))
dimnames(mat_rix) <- list(c("col_sums", "row1", "row2"),
                         c("row_sums", "col1", "col2", "col3"))
mat_rix
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{apply()} Functional with dots \texttt{"..."} Argument}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The dots \texttt{"..."} argument in \texttt{apply()} is designed to pass additional arguments to the function being called by \texttt{apply()}.
      \vskip1ex
      The additional arguments to \texttt{apply()} must be \emph{bound} by their full (complete) names.
      <<echo=TRUE,eval=FALSE>>=
str(apply)  # Get list of arguments
mat_rix <- matrix(sample(12), nrow=3, ncol=4)  # Create a matrix
mat_rix
apply(mat_rix, 2, sort)  # Sort matrix columns
apply(mat_rix, 2, sort, decreasing=TRUE)  # Sort decreasing order
      @
    \column{0.5\textwidth}
        <<echo=TRUE,eval=FALSE>>=
mat_rix[2, 2] <- NA  # Introduce NA value
mat_rix
# Calculate median of columns
apply(mat_rix, 2, median)
# Calculate median of columns with na.rm=TRUE
apply(mat_rix, 2, median, na.rm=TRUE)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{apply()} Functional with Anonymous Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The \texttt{apply()} functional combined with \emph{anonymous} functions can be used to loop over function parameters.
      \vskip1ex
      The dots \texttt{"..."} argument in \texttt{apply()} is designed to pass additional arguments to the function being called by \texttt{apply()}.
      \vskip1ex
      The additional arguments to \texttt{apply()} must be \emph{bound} by their full (complete) names.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=(-1)>>=
rm(list=ls())
# DAX percentage returns
re_turns <- rutils::diff_it(log(EuStockMarkets[, 1]))
library(moments)  # Load package moments
str(moment)  # Get list of arguments
# Apply moment function
moment(x=re_turns, order=3)
# 4x1 matrix of moment orders
moment_orders <- as.matrix(1:4)
# Anonymous function allows looping over function parameters
apply(X=moment_orders, MARGIN=1,
      FUN=function(moment_order) {
          moment(x=re_turns, order=moment_order)
        }  # end anonymous function
      )  # end apply

# Another way of passing parameters into moment() function
apply(X=moment_orders, MARGIN=1, FUN=moment,
      x=re_turns)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{apply()} Calling Functions with Multiple Arguments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      When \texttt{apply()} calls a function with multiple arguments, then care must be taken for proper argument binding.
      \vskip1ex
      The dots \texttt{"..."} argument in \texttt{apply()} allows passing additional arguments to the function being called by \texttt{apply()}.
      \vskip1ex
      The additional arguments to \texttt{apply()} must be \emph{bound} by their full (complete) names.
      \vskip1ex
      The values of the \texttt{"X"} argument in \texttt{apply()} are \emph{bound} by position to the first unused argument in the function being called by \texttt{apply()}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE>>=
# Function with three arguments
my_func <- function(arg1, arg2, arg3) {
  c(arg1=arg1, arg2=arg2, arg3=arg3)
}  # end my_func
my_func(1, 2, 3)
da_ta <- as.matrix(1:4)
# Pass da_ta to arg1
apply(X=da_ta, MAR=1, FUN=my_func, arg2=2, arg3=3)
# Pass da_ta to arg2
apply(X=da_ta, MAR=1, FUN=my_func, arg1=1, arg3=3)
# Pass da_ta to arg3
apply(X=da_ta, MAR=1, FUN=my_func, arg1=1, arg2=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{lapply()} Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The functional \texttt{lapply()} is a specialized version of the functional \texttt{apply()}.
      \vskip1ex
      \texttt{lapply()} applies a function to a list of objects and returns a list.
      \vskip1ex
      The function \texttt{unlist()} flattens a list into a vector that contains the atomic elements of the list.
      \vskip1ex
      {\color{red}{Rule of Thumb}}\\
      It's often better to use \texttt{lapply()}, since \texttt{apply()} and \texttt{sapply()} attempt to coerce their output into a vector or matrix, which may cause them to fail.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Vector of means of numeric columns
sapply(iris[, -5], mean)
# List of means of numeric columns
lapply(iris[, -5], mean)
# Lapply using anonymous function
unlist(lapply(iris,
              function(col_umn) {
                if (is.numeric(col_umn)) mean(col_umn)
              }  # end anonymous function
              )  # end lapply
       )  # end unlist
unlist(sapply(iris, function(col_umn) {
  if (is.numeric(col_umn)) mean(col_umn)}))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The \texttt{sapply()} Functional}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      The \texttt{sapply()} functional is a specialized version of the \texttt{apply()} functional.
      \vskip1ex
      \texttt{sapply()} applies a function to a vector or a list of objects and returns a vector or a list.
      \vskip1ex
      \texttt{sapply()} tries to return a vector, but if the elements can't be combined into a vector, then it returns a list.
      \vskip1ex
      When \texttt{sapply()} is given a data frame, it interprets it as a list, and applies the function to each element (column) of the data frame.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
sapply(6:10, sqrt)  # Sapply on vector
sapply(list(6, 7, 8, 9, 10), sqrt)  # Sapply on list

# Calculate means of iris data frame columns
sapply(iris, mean)  # Returns NA for Species

# Create a matrix
mat_rix <- matrix(sample(100), ncol=4)
# Calculate column means using apply
apply(mat_rix, 2, mean)

# Calculate column means using sapply, with anonymous function
sapply(1:NCOL(mat_rix),
       function(col_index) {  # Anonymous function
         mean(mat_rix[, col_index])
  }  # end anonymous function
)  # end sapply
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{\texttt{sapply()} Returning Matrices}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      If the function called by \texttt{sapply()} returns a vector, then \texttt{sapply()} returns a matrix, if possible.
      \vskip1ex
      The vectors returned by the function are arranged to form columns of the matrix returned by \texttt{sapply()}.
      \vskip1ex
      But if the function returns vectors of different lengths, then \texttt{sapply()} cannot return a matrix, and returns a list instead.
      \vskip1ex
      This behavior of \texttt{sapply()} can cause run-time errors.
      \vskip1ex
      The function \texttt{vapply()} is similar to \texttt{sapply()}, but it always attempts to simplify its output to a matrix, and if it can't then it produces an error.
      \vskip1ex
      \texttt{vapply()} requires the argument \texttt{FUN.VALUE} that specifes the output format of the function called by \texttt{vapply()}.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Vectors form columns of matrix returned by sapply
sapply(2:4, function(num) c(el1=num, el2=2*num))
# Vectors of different lengths returned as list
sapply(2:4, function(num) 1:num)
# vapply is similar to sapply
vapply(2:4, function(num) c(el1=num, el2=2*num),
       FUN.VALUE=c(row1=0, row2=0))
# vapply produces an error if it can't simplify
vapply(2:4, function(num) 1:num,
       FUN.VALUE=c(row1=0, row2=0))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Probability and Statistics}


%%%%%%%%%%%%%%%
\subsection{Pseudo-Random Numbers}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Pseudo-random numbers are deterministic sequences of numbers which have some of the properties of random numbers, but they are not truly random numbers.
      \vskip1ex
      Pseudo-random number generators depend on a \emph{seed} value, and produce the same sequence of numbers for a given \emph{seed} value.
      \vskip1ex
      The function \texttt{set.seed()} initializes the random number generator by specifying the \emph{seed} value.
      \vskip1ex
      The choice of \emph{seed} value isn't important, and a given value is just good as any other one.
      \vskip1ex
      The function \texttt{runif()} produces random numbers from the \emph{uniform} distribution.
      \vskip1ex
      The function \texttt{rnorm()} produces random numbers from the \emph{normal} distribution.
      \vskip1ex
      The function \texttt{dnorm()} calculates the normal probability density.
      \vskip1ex
      The function \texttt{pnorm()} calculates the cumulative \emph{normal} distribution.
      \vskip1ex
      The function \texttt{qnorm()} calculates the inverse cumulative \emph{normal} distribution.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
runif(3)  # three numbers from uniform distribution
runif(3)  # Produce another three numbers
set.seed(1121)  # Reset random number generator
runif(3)  # Produce another three numbers

# Produce random number from standard normal distribution
rnorm(1)
# Produce five random numbers from standard normal distribution
rnorm(5)
# Produce five random numbers from the normal distribution
rnorm(n=5, mean=1, sd=2)  # Match arguments by name
# Calculate cumulative standard normal distribution
c(pnorm(-2), pnorm(2))
# Calculate inverse cumulative standard normal distribution
c(qnorm(0.75), qnorm(0.25))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{The Logistic Map}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{logistic map} is a recurrence relation which produces a deterministic sequence of numbers:
      \begin{displaymath}
        x_{n+1} = r x_n (1 - x_n)
      \end{displaymath}
      If the \emph{seed} value $x_0$ is in the interval $(0, 1)$ and if $r=4$, then the sequence $x_n$ is also contained in the interval $(0, 1)$.
      \vskip1ex
      The function \texttt{curve()} plots a function defined by its name.
      <<echo=TRUE,eval=FALSE>>=
# Define logistic map function
log_map <- function(x, r=4) r*x*(1-x)
log_map(0.25, 4)
# Plot logistic map
x11(width=6, height=5)
curve(expr=log_map, type="l", xlim=c(0, 1),
      xlab="x[n-1]", ylab="x[n]", lwd=2, col="blue",
      main="logistic map")
lines(x=c(0, 0.25), y=c(0.75, 0.75), lwd=2, col="orange")
lines(x=c(0.25, 0.25), y=c(0, 0.75), lwd=2, col="orange")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/logistic_map.png}\\
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Generating Pseudo-Random Numbers Using Logistic Map}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{logistic map} can be used to calculate sequences of pseudo-random numbers.
      \vskip1ex
      For most \emph{seed} values $x_0$ and $r=4$, the \emph{logistic map} produces a pseudo-random sequence, but it's not uniformly distributed.
      \vskip1ex
      The inverse cosine function \texttt{acos()} transforms a \emph{logistic map} sequence into a uniformly distributed sequence,
      \begin{displaymath}
        u_n = \arccos(1 - 2 x_n) / \pi
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate uniformly distributed pseudo-random
# Sequence using logistic map function
uni_form <- function(see_d, len_gth=10) {
  # Pre-allocate vector instead of "growing" it
  out_put <- numeric(len_gth)
  # initialize
  out_put[1] <- see_d
  # Perform loop
  for (i in 2:len_gth) {
    out_put[i] <- 4*out_put[i-1]*(1-out_put[i-1])
  }  # end for
  acos(1-2*out_put)/pi
}  # end uni_form
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/logistic_map_density.png}\\
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
uni_form(see_d=0.1, len_gth=15)
plot(
  density(uni_form(see_d=runif(1), len_gth=1e5)),
  xlab="", ylab="", lwd=2, col="blue",
  main="uniform pseudo-random number density")
@
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Generating Binomial Random Numbers}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.4\textwidth}
      A \emph{binomial} trial is a coin flip, that results in either a success or failure.
      \vskip1ex
      The \emph{binomial} distribution specifies the probability of obtaining a certain number of successes in a sequence of independent \emph{binomial} trials.
      \vskip1ex
      Let $p$ be the probability of obtaining a success in a \emph{binomial} trial, and let $(1-p)$ be the probability of failure.
      \vskip1ex
      $p = 0.5$ corresponds to flipping an unbiased coin.
      \vskip1ex
      The probability of obtaining $k$ successes in $n$ independent \emph{binomial} trials is equal to:
      \begin{displaymath}
        {n \choose k} p^k (1-p)^{(n-k)}
      \end{displaymath}
      The function \texttt{rbinom()} produces random numbers from the \emph{binomial} distribution.
    \column{0.6\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Flip unbiased coin once, 20 times
rbinom(n=20, size=1, 0.5)
# Number of heads after flipping twice, 20 times
rbinom(n=20, size=2, 0.5)
# Number of heads after flipping thrice, 20 times
rbinom(n=20, size=3, 0.5)
# Number of heads after flipping biased coin thrice, 20 times
rbinom(n=20, size=3, 0.8)
# Number of heads after flipping biased coin thrice, 20 times
rbinom(n=20, size=3, 0.2)
# Flip unbiased coin once, 20 times
sample(x=0:1, size=20, replace=TRUE)  # Fast
as.numeric(runif(20) < 0.5)  # Slower
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Generating Random Samples and Permutations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A \emph{sample} is a subset of elements taken from a set of data elements.
      \vskip1ex
      The function \texttt{sample()} produces a random sample form a vector of data elements.
      \vskip1ex
      By default the \emph{size} of the sample (the \texttt{size} argument) is equal to the number of elements in the data vector.
      \vskip1ex
      So the call \texttt{sample(da\_ta)} produces a random permutation of all the elements of \texttt{da\_ta}.
      \vskip1ex
      If \texttt{replace=TRUE}, then \texttt{sample()} produces samples with replacement.
      \vskip1ex
      \emph{Monte Carlo} simulation consists of generating random samples from a given probability distribution.
      \vskip1ex
      The \emph{Monte Carlo} data samples can then used to calculate different parameters of the probability distribution (moments, quantiles, etc.), and its functionals.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=TRUE,eval=FALSE>>=
# Permutation of five numbers
sample(x=5)
# Permutation of four strings
sample(x=c("apple", "grape", "orange", "peach"))
# Sample of size three
sample(x=5, size=3)
# Sample with replacement
sample(x=5, replace=TRUE)
sample(  # Sample of strings
  x=c("apple", "grape", "orange", "peach"),
  size=12,
  replace=TRUE)
# Binomial sample: flip coin once, 20 times
sample(x=0:1, size=20, replace=TRUE)
# Flip unbiased coin once, 20 times
as.numeric(runif(20) > 0.5)  # Slower
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Statistical Estimators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      A data \emph{sample} is a set of observations of a \emph{random variable}.
      \vskip1ex
      Let $\{x_1,\ldots ,x_n\}$ be a data \emph{sample} of a \emph{random variable} \texttt{x}.
      \vskip1ex
      Let \texttt{x} follow a probability distribution with population \emph{mean} equal to $\mu$ and population standard deviation equal to $\sigma$.
      \vskip1ex
      A \emph{statistic} is a function of a data \emph{sample}:  $f( x_1,\ldots ,x_n )$.
      \vskip1ex
      A \emph{statistic} is itself a \emph{random variable}.
      \vskip1ex
      A statistical \emph{estimator} is a \emph{statistic} that provides an estimate of a \emph{distribution} parameter.
      \vskip1ex
      For example:
      \begin{displaymath}
        \bar{x} = \frac{1}{n}{\sum_{i=1}^n x_i}
      \end{displaymath}
      Is an \emph{estimator} of the \emph{mean} of the \emph{distribution}.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:2))>>=
rm(list=ls())
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
sam_ple <- rnorm(1000)

mean(sam_ple)  # Sample mean

median(sam_ple)  # Sample median

sd(sam_ple)  # Sample standard deviation
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Estimators of Higher Moments}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The estimators of moments of a probability distribution, based on a \emph{sample} of data, are given by:
      \vskip1ex
      Sample mean: $\bar{x}=\frac{1}{n} \sum_{i=1}^n x_i$
      \vskip1ex
      Sample variance: $\hat\sigma^2=\frac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})^2$
      \vskip1ex
      With their expected values equal to the population mean and standard deviation:\\
      $\mathbb{E}[\bar{x}] = \mu$ \hskip0.5em and \hskip0.5em $\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma\mathbb{E}[\hat\sigma] = \sigma$
      \vskip1ex
      The sample skewness (third moment) is equal to:
      \begin{displaymath}
        \hat{s}=\frac{n}{(n-1)(n-2)} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^3
      \end{displaymath}
      The sample kurtosis (fourth moment) is equal to
      \begin{displaymath}
        \hat{k}=\frac{n}{(n-1)^2} \sum_{i=1}^n (\frac{x_i-\bar{x}}{\hat\sigma})^4
      \end{displaymath}
      The normal distribution has zero skewness and kurtosis equal to 3.
    \column{0.5\textwidth}
      \vspace{-1em}
        <<echo=(-(1:1)),eval=FALSE>>=
rm(list=ls())
# DAX returns
re_turns <- diff(log(EuStockMarkets[, 1]))
# Number of observations
n_rows <- NROW(re_turns)
# Mean of DAX returns
mea_n <- mean(re_turns)
# Standard deviation of DAX returns
s_d <- sd(re_turns)
# Normalize returns
re_turns <- (re_turns - mea_n)/s_d
# Skew of DAX returns
skew(re_turns)
# Or
n_rows/((n_rows-1)*(n_rows-2))*sum(re_turns^3)
# Kurtosis of DAX returns
kurt(re_turns)
# Or
n_rows/(n_rows-1)^2*sum(re_turns^4)
# Random normal returns
re_turns <- rnorm(n_rows, sd=2)
# Mean and standard deviation of random normal returns
mean(re_turns); sd(re_turns)
# Skew and kurtosis of random normal returns
skew(re_turns); kurt(re_turns)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Estimators of Quantiles}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{quantile} of a probability distribution is the value of the \emph{random variable} \texttt{x}, such that the probability of values less than \texttt{x} is equal to the given \emph{probability} $p$.
      \vskip1ex
      The \emph{quantile} of a data sample can be calculated by first sorting the sample, and then finding the value corresponding closest to the given \emph{probability} $p$.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles, but it's quite slow.
      \vskip1ex
      The function \texttt{sort()} returns a vector sorted into ascending order.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
len_gth <- 1000
sam_ple <- rnorm(len_gth)
# Sample mean - MC estimate
mean(sam_ple)
# Sample standard deviation - MC estimate
sd(sam_ple)
# Monte Carlo estimate of cumulative probability
sam_ple <- sort(sam_ple)
pnorm(1)
sum(sam_ple<1)/len_gth
# Monte Carlo estimate of quantile
conf_level <- 0.99
qnorm(conf_level)
cut_off <- conf_level*len_gth
sam_ple[cut_off]
quantile(sam_ple, probs=conf_level)
# Analyze the source code of quantile()
stats:::quantile.default
# microbenchmark quantile
library(microbenchmark)
summary(microbenchmark(
  sam_ple=sam_ple[cut_off],
  quan_tile=quantile(sam_ple, probs=conf_level),
  times=100))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of Estimators}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Statistical estimators are functions of samples (which are random variables), and therefore are themselves \emph{random variables}.
      \vskip1ex
      The \emph{standard error} (SE) of an estimator is defined as its \emph{standard deviation} (not to be confused with the \emph{population standard deviation} of the underlying random variable).
      \vskip1ex
      For example, the \emph{standard error} of the estimator of the mean is equal to:
      \begin{displaymath}
        \sigma_\mu = \frac{\sigma}{\sqrt{n}}
      \end{displaymath}
      Where $\sigma$ is the \emph{population standard deviation} (which is usually unkown).
      \vskip1ex
      The \emph{estimator} of this \emph{standard error} is equal to:
      \begin{displaymath}
        SE_{\mu} = \frac{\hat\sigma}{\sqrt{n}}
      \end{displaymath}
      where: $\hat\sigma^2=\frac{1}{n-1} \sum_{i=1}^n (x_i-\bar{x})^2$ is the sample standard deviation (the estimator of the population standard deviation).
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=(-(1:1)),eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
len_gth <- 1000
sam_ple <- rnorm(len_gth)
# Sample mean
mean(sam_ple)
# Sample standard deviation
sd(sam_ple)
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Simulation}


%%%%%%%%%%%%%%%
\subsection{Monte Carlo Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      \emph{Monte Carlo} simulation consists of generating random samples from a given probability distribution.
      \vskip1ex
      The \emph{Monte Carlo} data samples can then used to calculate different parameters of the probability distribution (moments, quantiles, etc.), and its functionals.
      \vskip1ex
      The \emph{quantile} of a probability distribution is the value of the \emph{random variable} \texttt{x}, such that the probability of values less than \texttt{x} is equal to the given \emph{probability} \texttt{p}.
      \vskip1ex
      The \emph{quantile} of a data sample can be calculated by first sorting the sample, and then finding the value corresponding closest to the given \emph{probability} \texttt{p}.
      \vskip1ex
      The function \texttt{quantile()} calculates the sample quantiles, but it's quite slow.
      \vskip1ex
      The function \texttt{sort()} returns a vector sorted into ascending order.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
n_rows <- 1000
sam_ple <- rnorm(n_rows)
# Sample mean - MC estimate
mean(sam_ple)
# Sample standard deviation - MC estimate
sd(sam_ple)
# Monte Carlo estimate of cumulative probability
sam_ple <- sort(sam_ple)
pnorm(1)
sum(sam_ple<1)/n_rows
# Monte Carlo estimate of quantile
conf_level <- 0.99
qnorm(conf_level)
cut_off <- conf_level*n_rows
sam_ple[cut_off]
quantile(sam_ple, probs=conf_level)
# Analyze the source code of quantile()
stats:::quantile.default
# Microbenchmark quantile
library(microbenchmark)
summary(microbenchmark(
  sam_ple=sam_ple[cut_off],
  quan_tile=quantile(sam_ple, probs=conf_level),
  times=100))[, c(1, 4, 5)]  # end microbenchmark summary
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Standard Errors of Estimators Using Bootstrap Simulation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The standard errors of estimators can be calculated using a \emph{bootstrap} simulation.
      \vskip1ex
      The \emph{bootstrap} procedure generates new data by randomly sampling with replacement from the observed (empirical) data set.
      \vskip1ex
      The \emph{bootstrapped} dataset is used to re-calculate the estimator many times, producing a vector of values.
      \vskip1ex
      The \emph{bootstrapped} estimator values are then used to calculate the probability distribution of the estimator and its standard error.
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
n_rows <- 1000; sam_ple <- rnorm(n_rows)
# Sample mean and standard deviation
mean(sam_ple); sd(sam_ple)
# Bootstrap of sample mean and median
boot_strap <- sapply(1:10000, function(x) {
  boot_sample <- sam_ple[sample.int(n_rows,
                                    replace=TRUE)]
  c(mean=mean(boot_sample), median=median(boot_sample))
})  # end sapply
boot_strap <- t(boot_strap)
      @
      \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/boot_median.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
boot_strap[1:3, ]
# Standard error from formula
sd(sam_ple)/sqrt(n_rows)
# Standard error of mean from bootstrap
sd(boot_strap[, "mean"])
# Standard error of median from bootstrap
sd(boot_strap[, "median"])
plot(density(boot_strap[, "median"]),
     lwd=2, xlab="regression slopes",
     main="Distribution of Bootstrapped Median")
abline(v=mean(boot_strap[, "median"]),
       lwd=2, col="red")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping From Random Data}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrapping is performed when it's not possible to obtain another set of empirical data, so we simulate a new data set by randomly sampling from the existing data.
      \vskip1ex
      But if the data consists of simulated random numbers then we can easily simulate another set of these random numbers, instead of sampling from the existing data.
      \vskip1ex
      The numbers won't be the same as before, but they will be statistically equivalent in the limit of many bootstrap simulations.
      \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
set.seed(1121)  # Reset random number generator
n_rows <- 1000
sam_ple <- rnorm(n_rows)
# Bootstrap of sample mean and median
boot_strap <- sapply(1:10000, function(x) {
  # Boot_sample from Standard Normal Distribution
  boot_sample <- rnorm(n_rows)
  c(mean=mean(boot_sample),
    median=median(boot_sample))
})  # end sapply
boot_strap[, 1:3]
# Standard error from formula
sd(sam_ple)/sqrt(n_rows)
# Standard error of mean from bootstrap
sd(boot_strap["mean", ])
# Standard error of median from bootstrap
sd(boot_strap["median", ])
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping Standard Errors Using Parallel Computing}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{bootstrap} procedure performs a loop, which naturally lends itself to parallel computing.
      \vskip1ex
      Different functions from package \emph{parallel} need to be called depending on the operating system (\emph{Windows}, \emph{Mac-OSX}, or \emph{Linux}).
      \vskip1ex
      The function \texttt{makeCluster()} starts running \texttt{R} processes on several CPU cores under \emph{Windows}.
      \vskip1ex
      The function \texttt{parLapply()} is similar to \texttt{lapply()}, and performs apply loops under \emph{Windows}, using parallel computing on several CPU cores.
      \vskip1ex
      The \texttt{R} processes started by \texttt{makeCluster()} don't inherit any data from the parent \texttt{R} process.
      \vskip1ex
      Therefore the required data must be passed into \texttt{parLapply()} via the dots \texttt{"..."} argument.
      \vskip1ex
      The function \texttt{mclapply()} performs apply loops using parallel computing on several CPU cores under \emph{Mac-OSX} or \emph{Linux}.
      \vskip1ex
      The function \texttt{stopCluster()} stops the \texttt{R} processes running on several CPU cores.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
library(parallel)  # Load package parallel
n_cores <- detectCores() - 1  # Number of cores
clus_ter <- makeCluster(n_cores)  # Initialize compute cluster under Windows
set.seed(1121)  # Reset random number generator
# Sample from Standard Normal Distribution
n_rows <- 1000
sam_ple <- rnorm(n_rows)
# Bootstrap mean and median under Windows
boot_strap <- parLapply(clus_ter, 1:10000,
  function(x, sam_ple, n_rows) {
  boot_sample <- sam_ple[sample.int(n_rows, replace=TRUE)]
  c(mean=mean(boot_sample), median=median(boot_sample))
  }, sam_ple=sam_ple, n_rows=n_rows)  # end parLapply
# Bootstrap mean and median under Mac-OSX or Linux
boot_strap <- mclapply(1:10000,
  function(x) {
  boot_sample <- sam_ple[sample.int(n_rows, replace=TRUE)]
  c(mean=mean(boot_sample), median=median(boot_sample))
  }, mc.cores=n_cores)  # end mclapply
boot_strap <- rutils::do_call(rbind, boot_strap)
# Means and standard errors from bootstrap
apply(boot_strap, MARGIN=2,
      function(x) c(mean=mean(x), std_error=sd(x)))
# Standard error from formula
sd(sam_ple)/sqrt(n_rows)
stopCluster(clus_ter)  # Stop R processes over cluster under Windows
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Parallel Bootstrapping of the \protect\emph{Median Absolute Deviation}}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{Median Absolute Deviation} (\emph{MAD}) is a robust measure of dispersion (variability), defined using the median instead of the mean:
      \begin{displaymath}
        \operatorname{MAD} = \operatorname{median}(\operatorname{abs}(x_i - \operatorname{median}(\mathbf{x})))
      \end{displaymath}
      The advantage of \emph{MAD} is that it's always well defined, even for data that has infinite variance.
      \vskip1ex
      For normally distributed data the \emph{MAD} has a larger standard error than the standard deviation.
      \vskip1ex
      But for distributions with fat tails (like asset returns), the standard deviation has a larger standard error than the \emph{MAD}.
      \vskip1ex
      The \emph{MAD} for normally distributed data is equal to $\Phi^{-1}(0.75) \cdot \hat\sigma = 0.6745 \cdot \hat\sigma$.
      \vskip1ex
      The function \texttt{mad()} calculates the \emph{MAD} and divides it by $\Phi^{-1}(0.75)$ to make it comparable to the standard deviation.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
n_rows <- 1000
sam_ple <- rnorm(n_rows)
sd(sam_ple)
mad(sam_ple)
median(abs(sam_ple - median(sam_ple)))
median(abs(sam_ple - median(sam_ple)))/qnorm(0.75)
# Bootstrap of sd and mad estimators
boot_strap <- sapply(1:10000, function(x) {
  boot_sample <-
    sam_ple[sample.int(n_rows, replace=TRUE)]
  c(sd=sd(boot_sample), mad=mad(boot_sample))
})  # end sapply
boot_strap <- t(boot_strap)
# Analyze bootstrapped variance
head(boot_strap)
sum(is.na(boot_strap))
# Means and standard errors from bootstrap
apply(boot_strap, MARGIN=2,
      function(x) c(mean=mean(x), std_error=sd(x)))
# Parallel bootstrap under Windows
library(parallel)  # Load package parallel
n_cores <- detectCores() - 1  # Number of cores
clus_ter <- makeCluster(n_cores)  # Initialize compute cluster
boot_strap <- parLapply(clus_ter, 1:10000,
  function(x, sam_ple) {
    boot_sample <- sam_ple[sample.int(n_rows, replace=TRUE)]
    c(sd=sd(boot_sample), mad=mad(boot_sample))
  }, sam_ple=sam_ple)  # end parLapply
# Parallel bootstrap under Mac-OSX or Linux
boot_strap <- mclapply(1:10000,
  function(x) {
    boot_sample <- sam_ple[sample.int(n_rows, replace=TRUE)]
    c(sd=sd(boot_sample), mad=mad(boot_sample))
  }, mc.cores=n_cores)  # end mclapply
stopCluster(clus_ter)  # Stop R processes over cluster
boot_strap <- rutils::do_call(rbind, boot_strap)
# Means and standard errors from bootstrap
apply(boot_strap, MARGIN=2,
      function(x) c(mean=mean(x), std_error=sd(x)))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Bootstrapping From Empirical Datasets}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Bootstrapping is usually performed by resampling from an observed (empirical) dataset.
      \vskip1ex
      Resampling consists of randomly selecting data from an existing dataset, with replacement.
      \vskip1ex
      Resampling produces a new \emph{bootstrapped} dataset with similar properties to the existing dataset.
      \vskip1ex
      The \emph{bootstrapped} dataset is used to re-calculate the estimator many times, producing a vector of values.
      \vskip1ex
      The \emph{bootstrapped} estimator values are then used to calculate the probability distribution of the estimator and its standard error.
      \vskip1ex
      Bootstrapping doesn't provide accurate estimates for estimators which are sensitive to the ordering and correlations in the data.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Sample from time series of ETF returns
re_turns <- rutils::etf_env$re_turns[, "VTI"]
re_turns <- na.omit(re_turns)
n_rows <- NROW(re_turns)
# Bootstrap sd and MAD under Windows
library(parallel)  # Load package parallel
n_cores <- detectCores() - 1  # Number of cores
clus_ter <- makeCluster(n_cores)  # Initialize compute cluster under Windows
clusterSetRNGStream(clus_ter, 1121)  # Reset random number generator in all cores
n_boot <- 1e4
boot_strap <- parLapply(clus_ter, 1:n_boot,
  function(x, re_turns, n_rows) {
    boot_sample <- re_turns[sample.int(n_rows, replace=TRUE)]
    c(sd=sd(boot_sample), mad=mad(boot_sample))
  }, re_turns=re_turns, n_rows=n_rows)  # end parLapply
# Bootstrap sd and MAD under Mac-OSX or Linux
boot_strap <- mclapply(1:n_boot,
  function(x) {
    boot_sample <- re_turns[sample.int(n_rows, replace=TRUE)]
    c(sd=sd(boot_sample), mad=mad(boot_sample))
  }, mc.cores=n_cores)  # end mclapply
stopCluster(clus_ter)  # Stop R processes over cluster under Windows
boot_strap <- rutils::do_call(rbind, boot_strap)
# Standard error assuming normal distribution of returns
sd(re_turns)/sqrt(n_boot)
# Means and standard errors from bootstrap
std_errors <- apply(boot_strap, MARGIN=2,
      function(x) c(mean=mean(x), std_error=sd(x)))
std_errors
# Relative standard errors
std_errors[2, ]/std_errors[1, ]
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Credit Portfolio Models}


%%%%%%%%%%%%%%%
\subsection{Simulating Single-period Defaults}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Consider a portfolio of credit assets (bonds or loans) over a single period of time.
      \vskip1ex
      At the end of the period, some of the assets default, while the rest don't.
      \vskip1ex
      The default probabilities are equal to $p_i$.
      \vskip1ex
      Individual defaults can be simulated by comparing the probabilities $p_i$ with the uniform random numbers $u_i$.
      \vskip1ex
      Default occurs if $u_i$ is less than the default probability $p_i$:
      \begin{displaymath}
        u_i < p_i
      \end{displaymath}
      Simulations in \texttt{R} can be accelerated by pre-computing a vector of random numbers, instead of generatng them one at a time in a loop.
      \vskip1ex
      Vectors of random numbers allow using \emph{vectorized} functions, instead of inefficient (slow) \texttt{for()} loops.
    \column{0.5\textwidth}
    \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate random default probabilities
n_assets <- 100
def_probs <- runif(n_assets, max=0.2)
mean(def_probs)
# Calculate number of defaults
uni_form <- runif(n_assets)
sum(uni_form < def_probs)
# Simulate average number of defaults
n_simu <- 1000
de_faults <- numeric(n_simu)
# Simulate using for() loop (inefficient way)
for (i in 1:n_simu) {  # Perform loop
  uni_form <- runif(n_assets)
  de_faults[i] <- sum(uni_form < def_probs)
}  # end for
# Calculate average number of defaults
mean(de_faults)
# Simulate using vectorized functions  (efficient way)
uni_form <- matrix(runif(n_simu*n_assets),
                   ncol=n_simu)
sum(uni_form < def_probs)/n_simu
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Values and Default Thresholds}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Defaults can also be simulated using normally distributed variables $a_i$ called \emph{asset values}, instead of uniformly distributed variables.
      \vskip1ex
      These asset values are mathematical variables, which can have negative values, so they are not related to actual company asset values, but may be thought of as related to the balance of company assets minus its liabilities.
      \vskip1ex
      Default occurs if the \emph{asset value} $a_i$ is less than the \emph{default threshold} $t_i$:
      \begin{displaymath}
        a_i < t_i
      \end{displaymath}
      The default threshold is equal to $t_i = \Phi^{-1}(p_i)$, where $p_i$ is the default probability, and $\Phi()$ is the cumulative standard normal distribution.
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_def_threshold.png}
    \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot Standard Normal distribution
curve(expr=dnorm(x),
      type="l", xlim=c(-4, 4),
      xlab="asset value", ylab="", lwd=2,
      col="blue", main="Distribution of Asset Values")
abline(v=qnorm(0.025), col="red", lwd=2)
text(x=qnorm(0.025)-0.1, y=0.15,
       labels="default threshold",
       lwd=2, srt=90, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vasicek Model of Correlated Asset Values}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under the \emph{Vasicek} single factor model, the asset value $a_i$ is equal to the sum of a \emph{systematic} factor $s$, plus an \emph{idiosyncratic} factor $z_i$:
      \begin{displaymath}
        a_i = \sqrt{\rho} s + \sqrt{1-\rho} z_i
      \end{displaymath}
      Where $\rho$ is the correlation between asset values.
      \vskip1ex
      The variables $s$, $z_i$, and $a_i$ all follow the Standard Normal distribution $N(0, 1)$.
      \vskip1ex
      The \emph{Vasicek} model resembles the \emph{CAPM} model, with the asset value (not the asset returns) equal to the sum of a \emph{systematic} factor plus an \emph{idiosyncratic} factor.
      \vskip1ex
      The Bank for International Settlements (BIS) uses the \emph{Vasicek} model as part of its regulatory capital requirements for credit risk:\\
\hskip1em\url{http://bis2information.org/content/Vasicek_model}\\
\hskip1em\url{https://www.bis.org/bcbs/basel3.htm}\\
\hskip1em\url{https://www.bis.org/bcbs/irbriskweight.pdf}
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define correlation parameters
rh_o <- 0.2
rho_sqrt <- sqrt(rh_o) ; rho_sqrtm <- sqrt(1-rh_o)
n_assets <- 5 ; n_simu <- 10000
# Calculate vector of systematic factors
system_atic <- rnorm(n_simu)
# Simulate asset values using vectorized functions (efficient way)
asset_s <- rho_sqrt*system_atic +
  rho_sqrtm*rnorm(n_simu*n_assets)
dim(asset_s) <- c(n_simu, n_assets)
# Calculate correlations between asset values
cor(asset_s)
# Simulate asset values using for() loop (inefficient way)
# allocate matrix of assets
asset_s <- matrix(nr=n_simu, nc=n_assets)
# Simulate asset values using for() loop
for (i in 1:n_simu) {  # Perform loop
  asset_s[i, ] <-
    rho_sqrt*system_atic[i] +
    rho_sqrtm*rnorm(n_assets)
}  # end for
cor(asset_s)
# benchmark the speed of the two methods
library(microbenchmark)
summary(microbenchmark(
  for_loop={for (i in 1:n_simu) {
    rho_sqrt*system_atic[i] +
    rho_sqrtm*rnorm(n_assets)}},
  vector_ized={rho_sqrt*system_atic +
              rho_sqrtm*rnorm(n_simu*n_assets)},
  times=10))[, c(1, 4, 5)]
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Vasicek Model of Correlated Defaults}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Under the \emph{Vasicek} model, default occurs if the \emph{asset value} $a_i$ is less than the \emph{default threshold} $t_i$:
      \begin{align*}
        a_i = \sqrt{\rho} s + \sqrt{1-\rho} z_i \\
        a_i < t_i
      \end{align*}
      The \emph{systematic} factor $s$ may be considered to represent the state of the macro economy, with positive values representing an economic expansion, and negative values representing an economic recession.
      \vskip1ex
      When the value of the \emph{systematic} factor $s$ is positive, then the asset values will all tend to be bigger as well, which will produce fewer defaults.
      \vskip1ex
      But when the \emph{systematic} factor is negative, then the asset values will tend to be smaller, which will produce more defaults.
      \vskip1ex
      This way the \emph{Vasicek} model introduces a correlation among defaults.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate random default probabilities
n_assets <- 5
def_probs <- runif(n_assets, max=0.2)
mean(def_probs)
# Calculate default thresholds
def_thresh <- qnorm(def_probs)
# Calculate number of defaults using vectorized functions (efficient way)
# Calculate vector of number of defaults
de_faults <-
  colSums(t(t(asset_s) < def_thresh))
de_faults / n_simu
def_probs
# Calculate number of defaults using for() loop (inefficient way)
# allocate matrix of de_faults
de_faults <- matrix(nr=n_simu, nc=n_assets)
# Simulate asset values using for() loop
for (i in 1:n_simu) {  # Perform loop
  de_faults[i, ] <-
    (asset_s[i, ] < def_thresh)
}  # end for
colSums(de_faults) / n_simu
def_probs
# Calculate correlations between defaults
cor(de_faults)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Asset Correlation and Default Correlation}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Default correlation is defined as the correlation between the \texttt{Boolean} vectors of default events.
      \vskip1ex
      The \emph{Vasicek} model introduces correlation among default events, through the correlation of \emph{asset values}.
      \vskip1ex
      If \emph{asset values} have a positive correlation, then the defaults among credits are clustered together, and if one credit defaults then the other credits are more likely to default as well.
      \vskip1ex
      Empirical studies have found that the asset correlation $\rho$ can vary between \texttt{5\%} to \texttt{20\%}, depending on the default risk.
      \vskip1ex
      Credits with higher default risk tend to also have higher asset correlation, since they are more  sensitive to the economic conditions.
      \vskip1ex
      Default correlations are usually much lower than the corresponding asset correlations.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define default probabilities
n_assets <- 2
def_prob <- 0.2
def_thresh <- qnorm(def_prob)
# Define correlation parameters
rh_o <- 0.2
rho_sqrt <- sqrt(rh_o) ; rho_sqrtm <- sqrt(1-rh_o)
# Calculate vector of systematic factors
n_simu <- 1000
system_atic <- rnorm(n_simu)
# Simulate asset values using vectorized functions
asset_s <- rho_sqrt*system_atic +
  rho_sqrtm*rnorm(n_simu*n_assets)
dim(asset_s) <- c(n_simu, n_assets)
# Calculate number of defaults using vectorized functions
de_faults <- t(t(asset_s) < def_thresh)
# Calculate correlations between defaults
cor(de_faults)
# Calculate average number of defaults and compare to def_prob
colSums(de_faults) / n_simu
def_prob
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Cumulative Defaults Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If all the default probabilities are the same $p_i=p$, then the default threshold is equal to $t=\Phi^{-1}(p)$, and the conditional default probability $p(s)$, given the systematic factor $s$, is equal to:
      \begin{displaymath}
        p(s) = \Phi(\frac{t - \sqrt{\rho} s}{\sqrt{1-\rho}})
      \end{displaymath}
      The cumulative probability $P(x)$ for the percentage \texttt{x} of portfolio defaults (the portfolio cumulative default distribution) is equal to:
      \begin{displaymath}
        P(x) = \Phi(\frac{{\sqrt{1-\rho}} \Phi^{-1}(x) - t}{\sqrt{\rho}})
      \end{displaymath}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Define cumulative default probability function
def_cumdistr <- function(x, def_thresh=(-2), rh_o=0.2)
  pnorm((sqrt(1-rh_o)*qnorm(x) - def_thresh)/sqrt(rh_o))
def_cumdistr(x=0.2, def_thresh=qnorm(def_prob), rh_o=rh_o)
# Plot cumulative default probability function
def_prob <- 0.4; def_thresh <- qnorm(def_prob)
curve(expr=def_cumdistr(x, def_thresh=def_thresh, rh_o=0.05),
      xlim=c(0, 0.999), lwd=3,
      xlab="percent default", ylab="probability",
      col="green", main="Cumulative Default Probabilities")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_cum_def.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with higher correlation
curve(expr=def_cumdistr(x, def_thresh=def_thresh, rh_o=0.2),
      xlim=c(0, 0.999), add=TRUE, lwd=3,
      col="blue", main="")
# Add legend
legend(x="topleft",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.05, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=def_prob, col="red", lwd=3)
text(x=def_prob, y=0.0,
       labels="default probability",
       lwd=2, srt=90, pos=4)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Defaults Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The probability density $f(x)$ of portfolio defaults is equal to the derivative of the cumulative default distribution:
      \begin{multline*}
        \hspace{-1.7em}f(x) = \frac{\sqrt{1-\rho}}{\sqrt{\rho}} \exp(-\frac{1}{2 \rho} ({\sqrt{1-\rho}} \Phi^{-1}(x) - t)^2 + \\ \frac{1}{2} {\Phi^{-1}(x)^2)}
      \end{multline*}
      <<echo=TRUE,eval=FALSE>>=
# Define default probability density function
def_distr <- function(x, def_thresh=(-2), rh_o=0.2)
  sqrt((1-rh_o)/rh_o)*exp(-(sqrt(1-rh_o)*qnorm(x) -
  def_thresh)^2/(2*rh_o) + qnorm(x)^2/2)
# Define parameters
rh_o <- 0.2 ; rho_sqrt <- sqrt(rh_o) ; rho_sqrtm <- sqrt(1-rh_o)
def_prob <- 0.3; def_thresh <- qnorm(def_prob)
def_distr(0.03, def_thresh=def_thresh, rh_o=rh_o)
# Plot probability distribution of defaults
curve(expr=def_distr(x, def_thresh=def_thresh, rh_o=0.1),
      xlim=c(0, 1.0), lwd=3,
      xlab="percentage of defaults", ylab="density",
      col="green", main="Distribution of Defaults")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_distr_def.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with higher correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rh_o=0.3),
      xlab="default percentage", ylab="",
      add=TRUE, lwd=3, col="blue", main="")
# Add legend
legend(x="topright",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.05, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=def_prob, col="red", lwd=3)
text(x=def_prob, y=2,
       labels="default probability",
       lwd=2, srt=90, pos=2)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Distribution of Defaults Under Extreme Correlations}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the correlation $\rho$ is close to \emph{zero}, then the asset values $a_i$ are independent from each other, and defaults are also independent, so that the percentage of portfolio defaults is very close to the default probability $p$.
      \vskip1ex
      In that case, the probability density of portfolio defaults is very narrow and is centered on the default probability $p$.
      \vskip1ex
      If the correlation $\rho$ is close to \emph{one}, then the asset values $a_i$ are almost the same, and defaults occur at the same time, so that the percentage of portfolio defaults is either \emph{zero} or \emph{one}.
      \vskip1ex
      In that case, the probability density of portfolio defaults becomes \emph{bimodal}, with two peaks around  \emph{zero} and \emph{one}.
      <<echo=TRUE,eval=FALSE>>=
# Plot default distribution with low correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rh_o=0.01),
      xlab="default percentage", ylab="", lwd=2,
      col="green", main="Distribution of Defaults")
# Plot default distribution with high correlation
curve(expr=def_distr(x, def_thresh=def_thresh, rh_o=0.99),
      xlab="percentage of defaults", ylab="density",
      add=TRUE, lwd=2, n=10001, col="blue", main="")
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_high_corr.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Add legend
legend(x="top",
       legend=c("high correlation", "low correlation"),
       title=NULL, inset=0.1, cex=0.8, bg="white",
       bty="n", lwd=6, lty=1, col=c("blue", "green"))
# Add unconditional default probability
abline(v=0.1, col="red", lwd=2)
text(x=0.1, y=10, lwd=2, pos=4,
       labels="default probability")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Numerical Integration of Functions}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The function \texttt{integrate()} performs numerical integration of a function of a single variable, i.e. it calculates a definite integral over an integration interval.
      \vskip1ex
      Additional parameters can be passed to the integrated function through the dots \texttt{"..."} argument of the function \texttt{integrate()}.
      \vskip1ex
      The function \texttt{integrate()} accepts the integration limits \texttt{-Inf} and \texttt{Inf} equal to minus and plus infinity.
    \column{0.5\textwidth}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Get help for integrate()
?integrate
# Calculate slowly converging integral
func_tion <- function(x) {1/((x+1)*sqrt(x))}
integrate(func_tion, lower=0, upper=10)
integrate(func_tion, lower=0, upper=Inf)
# Integrate function with parameter lamb_da
func_tion <- function(x, lamb_da=1) {
  exp(-x*lamb_da)
}  # end func_tion
integrate(func_tion, lower=0, upper=Inf)
integrate(func_tion, lower=0, upper=Inf,
          lamb_da=2)
# Cumulative probability over normal distribution
pnorm(-2)
integrate(dnorm, low=2, up=Inf)
str(dnorm)
pnorm(-1)
integrate(dnorm, low=2, up=Inf, mean=1)
# Expected value over normal distribution
integrate(function(x) x*dnorm(x),
          low=2, up=Inf)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Loss Distribution}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The expected loss (\emph{EL}) of a credit portfolio is equal to the sum of default probabilities ($p_i$) multiplied by the loss given default (\emph{LGD}, also known as the loss severity):
      \begin{displaymath}
        EL = \sum_{i=1}^{n} p_i LGD_i
      \end{displaymath}
      If the \emph{LGD} amounts are all the same, then the \emph{portfolio loss distribution} can be obtained from the \emph{default distribution}, adjusted for the \emph{LGD}:
      \begin{multline*}
        \hspace{-1.7em}f(x) = \frac{\sqrt{1-\rho}}{LGD \sqrt{\rho}} \exp(-\frac{1}{2 \rho} ({\sqrt{1-\rho}} \Phi^{-1}(\frac{x}{LGD}) - t)^2 + \\ \frac{1}{2} {\Phi^{-1}(\frac{x}{LGD}))^2}
      \end{multline*}
      <<echo=TRUE,eval=FALSE>>=
rh_o <- 0.1; l_gd <- 0.4
# Define Vasicek loss distribution function
loss_distr <- function(x, def_thresh=(-2), rh_o=0.2, l_gd=0.4)
  sqrt((1-rh_o)/rh_o)*exp(-(sqrt(1-rh_o)*qnorm(x/l_gd) - def_thresh)^2/(2*rh_o) + qnorm(x/l_gd)^2/2)/l_gd
integrate(loss_distr, low=0, up=l_gd,
  def_thresh=(-2), rh_o=rh_o, l_gd=l_gd)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_loss_distr.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Plot probability distribution of losses
def_prob <- 0.05; def_thresh <- qnorm(def_prob)
curve(expr=loss_distr(x, def_thresh=def_thresh, rh_o=rh_o),
      type="l", xlim=c(0, 0.06),
      xlab="loss percentage", ylab="density", lwd=3,
      col="orange", main="Distribution of Losses")
# Add line for expected loss
abline(v=l_gd*def_prob, col="red", lwd=3)
text(x=l_gd*def_prob-0.001, y=10, labels="expected loss",
       lwd=2, srt=90, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Portfolio Value at Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Value at Risk (\emph{VaR}) measures extreme portfolio loss (but not the worst possible loss), defined as the \emph{quantile} of the loss distribution, corresponding to a given confidence level $\alpha$.
      \vskip1ex
      A loss exceeding the \emph{EL} is called the Unexpected Loss (\emph{UL}), and can be calculated from the \emph{portfolio loss distribution}.
      <<echo=TRUE,eval=FALSE>>=
# Add lines for unexpected loss
abline(v=0.04, col="blue", lwd=3)
arrows(x0=0.02, y0=35, x1=0.04, y1=35,
       code=3, lwd=3, cex=0.5)
text(x=0.03, y=36, labels="unexpected loss",
     lwd=2, pos=3)
# Add lines for VaR
abline(v=0.055, col="red", lwd=3)
arrows(x0=0.0, y0=25, x1=0.055, y1=25,
       code=3, lwd=3, cex=0.5)
text(x=0.03, y=26, labels="VaR", lwd=2, pos=3)
text(x=0.055-0.001, y=10, labels="VaR",
       lwd=2, srt=90, pos=3)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_distr_var.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The Conditional Value at Risk (\emph{CVaR}) is equal to the average of the \emph{VaR} for confidence levels less than a given confidence level $\alpha$:
      \begin{displaymath}
        \mathrm{CVaR} = \frac{1}{\alpha} \int_{0}^{\alpha} {\mathrm{VaR}(p) \, \mathrm{d}p} = \frac{1}{\alpha} \int_{\mathrm{VaR}}^{LGD} {x \, f(x) \, \mathrm{d}x}
      \end{displaymath}
      The Conditional Value at Risk is also called the Expected Shortfall (\emph{ES}), or Expected Tail Loss (\emph{ETL}).
      <<echo=TRUE,eval=FALSE>>=
va_r <- 0.04; var_max <- 4*l_gd*def_prob
# Calculate CVaR
c_var <- integrate(function(x, ...) x*loss_distr(x, ...),
  low=va_r, up=l_gd, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)$value
c_var <- c_var/integrate(loss_distr, low=va_r, up=l_gd, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)$value
# Plot probability distribution of losses
curve(expr=loss_distr(x, def_thresh=def_thresh, rh_o=rh_o),
      type="l", xlim=c(0, 0.06),
      xlab="loss percentage", ylab="density", lwd=3,
      col="orange", main="Conditional Value at Risk")
# Add line for expected loss
abline(v=l_gd*def_prob, col="red", lwd=3)
text(x=l_gd*def_prob-0.001, y=10, labels="expected loss",
       lwd=2, srt=90, pos=3)
      @
    \column{0.5\textwidth}
      \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_distr_cvar.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Add lines for VaR
abline(v=va_r, col="red", lwd=3)
text(x=va_r-0.001, y=10, labels="VaR",
       lwd=2, srt=90, pos=3)
# Add shading for CVaR
var_s <- seq(va_r, var_max, length=100)
dens_ity <- sapply(var_s, loss_distr,
  def_thresh=def_thresh, rh_o=rh_o)
# Draw shaded polygon
polygon(c(va_r, var_s, var_max), density=20,
  c(-1, dens_ity, -1), col="red", border=NA)
text(x=va_r+0.005, y=0, labels="CVaR", lwd=2, pos=3)
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      Value at Risk (\emph{VaR}) measures extreme portfolio loss (but not the worst possible loss), defined as the \emph{quantile} of the loss distribution, corresponding to a given confidence level $\alpha$.
      \vskip1ex
      The \emph{quantile} of the loss distribution (the \emph{VaR}), for a given a confidence level $\alpha$, is given by the inverse of the cumulative loss distribution:
      \begin{displaymath}
        VaR(\alpha) = LGD \cdot \Phi(\frac{{\sqrt{\rho}} \Phi^{-1}(\alpha) + t}{\sqrt{1-\rho}})
      \end{displaymath}
      <<echo=TRUE,eval=FALSE>>=
# VaR (quantile of the loss distribution)
var_func <- function(x, def_thresh=qnorm(0.1), rh_o=0.1, l_gd=0.4)
  l_gd*pnorm((sqrt(rh_o)*qnorm(x) + def_thresh)/sqrt(1-rh_o))
var_func(x=0.99, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)
# Plot VaR
curve(expr=var_func(x, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd),
      type="l", xlim=c(0, 0.999),
      xlab="confidence level", ylab="VaR", lwd=3,
      col="orange", main="VaR versus Confidence Level")
# Add line for expected loss
abline(h=l_gd*def_prob, col="red", lwd=3)
text(x=0.2, y=l_gd*def_prob, labels="expected loss",
     lwd=2, pos=3)
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_var.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Value at Risk and Confidence Levels}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The confidence levels of \emph{VaR} values can also be calculated by integrating over the tail of the loss density function.
      <<echo=TRUE,eval=FALSE>>=
# Integrate loss_distr() over full range
integrate(loss_distr, low=0.0, up=l_gd,
          def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)
# Calculate expected losses using loss_distr()
integrate(function(x, ...) x*loss_distr(x, ...),
          low=0.0, up=l_gd,
          def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)
# Calculate confidence levels corresponding to VaR values
var_s <- seq(0.07, 0.12, 0.001)
level_s <- sapply(var_s, function(va_r, ...) {
  integrate(loss_distr, low=va_r, up=l_gd, ...)
}, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)  # end sapply
level_s <- cbind(as.numeric(t(level_s)[, 1]), var_s)
colnames(level_s) <- c("level_s", "VaRs")
# Calculate 95% confidence level VaR value
level_s[
  match(TRUE, level_s[, "level_s"] < 0.05), "VaRs"]
plot(x=1-level_s[, "level_s"],
     y=level_s[, "VaRs"], lwd=2,
     xlab="Confidence Levels", ylab="VaRs",
     t="l", main="VaR Values and Confidence Levels")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_var_conf.png}
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Conditional Value at Risk Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CVaR} values can be calculated by integrating over the tail of the loss density function.
      <<echo=TRUE,eval=FALSE>>=
# Calculate CVaR values
cvar_s <- sapply(var_s, function(va_r, ...) {
  integrate(function(x, ...) x*loss_distr(x, ...),
            low=va_r, up=l_gd, ...)
}, def_thresh=def_thresh, rh_o=rh_o, l_gd=l_gd)  # end sapply
level_s <- cbind(level_s, as.numeric(t(cvar_s)[, 1]))
colnames(level_s)[3] <- "CVaRs"
# Divide CVaR by confidence level
level_s[, "CVaRs"] <-
  level_s[, "CVaRs"]/level_s[, "level_s"]
# Calculate 95% confidence level CVaR value
level_s[match(TRUE,
  level_s[, "level_s"] < 0.05), "CVaRs"]
# Plot CVaRs
plot(x=1-level_s[, "level_s"],
     y=level_s[, "CVaRs"],
     t="l", col="red", lwd=2,
     ylim=range(level_s[, c("VaRs", "CVaRs")]),
     xlab="Confidence Levels", ylab="CVaRs",
     main="CVaR Values and Confidence Levels")
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_cvar_levels.png}
      \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Add VaRs
lines(x=1-level_s[, "level_s"],
      y=level_s[, "VaRs"], lwd=2)
# Add legend
legend(x="topleft", legend=c("CVaRs", "VaRs"),
       title="default probability = 5%
correlation = 10%
loss given default = 40%",
       inset=0.1, cex=0.8, bg="white", bty="n",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating \protect\emph{VaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      If the default probabilities $p_i$ are not all the same, then there's no formula for the \emph{portfolio loss distribution} under the Vasicek Model.
      \vskip1ex
      In that case the portfolio losses and \emph{VaR} must be simulated.
      <<echo=TRUE,eval=FALSE>>=
# Define model parameters
n_assets <- 300; n_simu <- 1000; l_gd <- 0.4
# Define correlation parameters
rh_o <- 0.2; rho_sqrt <- sqrt(rh_o); rho_sqrtm <- sqrt(1-rh_o)
# Calculate default probabilities and thresholds
set.seed(1121)
def_probs <- runif(n_assets, max=0.2)
def_thresh <- qnorm(def_probs)
# Calculate vector of systematic factors
system_atic <- rnorm(n_simu)
# Simulate losses under Vasicek model
asset_s <-
  matrix(rnorm(n_simu*n_assets), ncol=n_simu)
asset_s <-
  t(rho_sqrt*system_atic + t(rho_sqrtm*asset_s))
loss_es <-
  l_gd*colSums(asset_s < def_thresh)/n_assets
      @
    \column{0.5\textwidth}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_var_simu.png}
      \vspace{-1em}
      <<echo=TRUE,eval=FALSE>>=
# Calculate VaRs
level_s <- seq(0.93, 0.99, 0.01)
var_s <- quantile(loss_es, probs=level_s)
plot(x=level_s, y=var_s, t="l", lwd=2,
     xlab="Confidence Levels", ylab="VaRs",
     main="Simulated VaR and Confidence Levels")
      @
  \end{columns}
\end{block}

\end{frame}


%%%%%%%%%%%%%%%
\subsection{Simulating \protect\emph{CVaR} Under the Vasicek Model}
\begin{frame}[fragile,t]{\subsecname}
\vspace{-1em}
\begin{block}{}
  \begin{columns}[T]
    \column{0.5\textwidth}
      The \emph{CVaR} can be calculated from the frequency of tail losses in excess of the \emph{VaR}.
      \vskip1ex
      The function \texttt{table()} calculates the frequency distribution of categorical data.
      <<echo=TRUE,eval=FALSE>>=
# Calculate CVaRs
cvar_s <- sapply(var_s, function(va_r) {
  mean(loss_es[loss_es >=va_r])
})  # end sapply
cvar_s <- cbind(cvar_s, var_s)
# Alternative CVaR calculation using frequency table
# first calculate frequency table of loss_es
# ta_ble <- table(loss_es)/n_simu
# Calculate CVaRs from frequency table
# Cvar_s <- sapply(var_s, function(va_r) {
#   tai_l <- ta_ble[names(ta_ble) > va_r]
#   tai_l %*% as.numeric(names(tai_l)) / sum(tai_l)
# })  # end sapply
# Plot CVaRs
plot(x=level_s, y=cvar_s[, "cvar_s"],
     t="l", col="red", lwd=2,
     ylim=range(cvar_s),
     xlab="Confidence Levels", ylab="CVaRs",
     main="Simulated CVaR and Confidence Levels")
      @
    \column{0.5\textwidth}
    \vspace{-1em}
      \includegraphics[width=0.5\paperwidth]{figure/vasicek_cvar_simu.png}
    \vspace{-2em}
      <<echo=TRUE,eval=FALSE>>=
# Add VaRs
lines(x=level_s, y=cvar_s[, "var_s"], lwd=2)
# Add legend
legend(x="topleft", legend=c("CVaRs", "VaRs"), bty="n",
       title=NULL, inset=0.05, cex=0.8, bg="white",
       lwd=6, lty=1, col=c("red", "black"))
      @
  \end{columns}
\end{block}

\end{frame}



%%%%%%%%%%%%%%%
\section{Homework Assignment}


%%%%%%%%%%%%%%%
\subsection{Homework Assignment}
\begin{frame}[t]{\secname}
\vspace{-1em}
\begin{block}{Required}
  \begin{itemize}[]
    \item Study all the lecture slides in \emph{FRE6871\_Lecture\_2.pdf}, and run all the code in \emph{FRE6871\_Lecture\_2.R},
    \item Study \emph{bootstrap simulation} from the files \emph{bootstrap\_technique.pdf} and \emph{doBootstrap\_primer.pdf},
    \item Study the \emph{Vasicek} single factor model from \emph{Vasicek Portfolio Default Distribution.pdf},
    \item Study credit portfolio risk models from \texttt{BOE Credit Risk Models.pdf} and \texttt{BIS Bank Capital Model.pdf},
    \item Study CDO models from \texttt{Elizalde CDO Vasicek Credit Model.pdf},
    \item Study the \emph{CVAR} credit portfolio risk measure from \emph{Danielsson CVAR Estimation Standard Error.pdf}.
  \end{itemize}
\end{block}
\begin{block}{Recommended}
  \begin{itemize}[]
    \item Read about plotting from \emph{plot par cheatsheet.pdf} and \emph{ggplot2 cheatsheet.pdf}.
  \end{itemize}
\end{block}

\end{frame}


\end{document}
